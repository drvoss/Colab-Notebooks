{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drvoss/Colab-Notebooks/blob/master/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "1dd6_YiMqUSy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/lucidfrontier45/PyTorch-Book/raw/master/data/taco_and_burrito.tar.gz\n",
        "!tar -zxvf taco_and_burrito.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vIYqqRcNrqFQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "9a322ce4-4c89-433d-e3c4-a9222216e6dd"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import (Dataset,DataLoader,TensorDataset)\n",
        "import tqdm\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "# ImageFolder 함수를 사용해서 Dataset 작성\n",
        "train_imgs = ImageFolder(\"/content/taco_and_burrito/train/\"\n",
        "                         , transform=transforms.Compose([transforms.RandomCrop(224), transforms.ToTensor()]))\n",
        "test_imgs = ImageFolder(\"/content/taco_and_burrito/test/\"\n",
        "                        , transform=transforms.Compose([transforms.CenterCrop(224), transforms.ToTensor()]))\n",
        "# DataLoader 작성\n",
        "train_loader = DataLoader(train_imgs, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_imgs, batch_size=32, shuffle=False)\n",
        "\n",
        "from torchvision import models\n",
        "\n",
        "def eval_net(net, data_loader, device=\"cpu\"):\n",
        "  # Dropout 및 BatchNorm을 무효화\n",
        "  net.eval()\n",
        "  ys = []\n",
        "  ypreds = []\n",
        "  for x, y in data_loader:\n",
        "    # to 메서드로 계산을 실행할 디바이스로 전송\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    # 확률이 가장 큰 분류를 예측(리스트 2.1 참조)\n",
        "    # 여기선 forward（추론） 계산이 전부이므로 자동 미분에\n",
        "    # 필요한 처리는 off로 설정해서 불필요한 계산을 제한다\n",
        "    with torch.no_grad():\n",
        "      _, y_pred = net(x).max(1)\n",
        "    ys.append(y)\n",
        "    ypreds.append(y_pred)\n",
        "    \n",
        "  # 미니 배치 단위의 예측 결과 등을 하나로 묶는다\n",
        "  ys = torch.cat(ys)\n",
        "  ypreds = torch.cat(ypreds)\n",
        "  # 예측 정확도 계산\n",
        "  acc = (ys == ypreds).float().sum() / len(ys)\n",
        "  return acc.item()\n",
        "\n",
        "def train_net(net, train_loader, test_loader,only_fc=True\n",
        "              , optimizer_cls=optim.Adam, loss_fn=nn.CrossEntropyLoss()\n",
        "              , n_iter=10, device=\"cpu\"):\n",
        "  train_losses = []\n",
        "  train_acc = []\n",
        "  val_acc = []\n",
        "  if only_fc:\n",
        "    # 마지막 선형 계층의 파라미터만\n",
        "    # optimizer에 전달\n",
        "    optimizer = optimizer_cls(net.fc.parameters())\n",
        "  else:\n",
        "    optimizer = optimizer_cls(net.parameters())\n",
        "  for epoch in range(n_iter):\n",
        "    running_loss = 0.0\n",
        "    # 신경망을 훈련 모드로 설정\n",
        "    net.train()\n",
        "    n = 0\n",
        "    n_acc = 0\n",
        "    # 시간이 많이 걸리므로 tqdm을 사용해서 진행 바를 표시\n",
        "    for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n",
        "      total=len(train_loader)):\n",
        "      xx = xx.to(device)\n",
        "      yy = yy.to(device)\n",
        "      h = net(xx)\n",
        "      loss = loss_fn(h, yy)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "      n += len(xx)\n",
        "      _, y_pred = h.max(1)\n",
        "      n_acc += (yy == y_pred).float().sum().item()\n",
        "    train_losses.append(running_loss / i)\n",
        "    # 훈련 데이터의 예측 정확도\n",
        "    train_acc.append(n_acc / n)\n",
        "    \n",
        "    # 검증 데이터의 예측 정확도\n",
        "    val_acc.append(eval_net(net, test_loader, device))\n",
        "    # epoch의 결과 표시\n",
        "    print(epoch, train_losses[-1], train_acc[-1],\n",
        "      val_acc[-1], flush=True)\n",
        "\n",
        "\"\"\"\n",
        "# 사전 학습이 완료된 resnet18 불러오기\n",
        "net = models.resnet18(pretrained=True)\n",
        "# 모든 파라미터를 미분 대상에서 제외한다\n",
        "for p in net.parameters():\n",
        "  p.requires_grad=False\n",
        "# 마지막 선형 계층을 변경한다\n",
        "fc_input_dim = net.fc.in_features\n",
        "net.fc = nn.Linear(fc_input_dim, 2)\n",
        "# 신경망의 모든 파라미터를 GPU로 전송\n",
        "net.to(\"cuda:0\")\n",
        "# 훈련 실행\n",
        "train_net(net, train_loader, test_loader, n_iter=20, device=\"cuda:0\")\n",
        "\"\"\"\n",
        "# (N, C, H, W)형식의 텐서를(N, C*H*W)로 늘리는 계층\n",
        "# 합성곱 출력을 MLP에 전달할 때 필요\n",
        "class FlattenLayer(nn.Module):\n",
        "  def forward(self, x):\n",
        "    sizes = x.size()\n",
        "    return x.view(sizes[0], -1)\n",
        "\n",
        "class IdentityLayer(nn.Module):\n",
        "  def forward(self, x):\n",
        "    return x\n",
        "  \n",
        "net = models.resnet18(pretrained=True)\n",
        "for p in net.parameters():\n",
        "  p.requires_grad=False\n",
        "net.fc = IdentityLayer()\n",
        "\n",
        "conv_net = nn.Sequential(\n",
        "  nn.Conv2d(3, 32, 5),\n",
        "  nn.MaxPool2d(2),\n",
        "  nn.ReLU(),\n",
        "  nn.BatchNorm2d(32),\n",
        "  nn.Conv2d(32, 64, 5),\n",
        "  nn.MaxPool2d(2),\n",
        "  nn.ReLU(),\n",
        "  nn.BatchNorm2d(64),\n",
        "  nn.Conv2d(64, 128, 5),\n",
        "  nn.MaxPool2d(2),\n",
        "  nn.ReLU(),\n",
        "  nn.BatchNorm2d(128),\n",
        "  FlattenLayer()\n",
        ")\n",
        "# 합성곱에 의해 최종적으로 어떤 크기인지\n",
        "# 실제로 데이터를 넣어서 확인\n",
        "test_input = torch.ones(1, 3, 224, 224)\n",
        "conv_output_size = conv_net(test_input).size()[-1]\n",
        "# 최종 CNNN\n",
        "net = nn.Sequential(\n",
        "  conv_net,\n",
        "  nn.Linear(conv_output_size, 2)\n",
        ")\n",
        "\n",
        "# 신경망의 모든 파라미터를 GPU로 전송\n",
        "net.to(\"cuda:0\")\n",
        "\n",
        "# 훈련 실행\n",
        "train_net(net, train_loader, test_loader, n_iter=10, only_fc=False, device=\"cuda:0\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:06<00:00,  3.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 2.708134201439944 0.550561797752809 0.4833333492279053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:05<00:00,  3.88it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 2.346039907498793 0.6095505617977528 0.5333333611488342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:05<00:00,  4.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2 2.494360002604398 0.6179775280898876 0.550000011920929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:05<00:00,  4.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3 2.260109148242257 0.6390449438202247 0.6666666865348816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:05<00:00,  3.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4 2.2900000566785987 0.648876404494382 0.6166666746139526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:06<00:00,  3.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5 2.4668075415221127 0.6207865168539326 0.7500000596046448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:05<00:00,  3.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6 2.5537304918874395 0.6306179775280899 0.5166667103767395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:05<00:00,  3.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7 1.9943181682716717 0.6769662921348315 0.5666667222976685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:06<00:00,  3.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8 2.1651138988408176 0.6193820224719101 0.6833333969116211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:05<00:00,  3.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9 2.6410754214633596 0.6587078651685393 0.6666666865348816\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}