{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_encoder-decoder_EnglishToSpainish.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drvoss/Colab-Notebooks/blob/master/RNN_encoder_decoder_EnglishToSpainish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Vtj5aKBVHuFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "2ef20223-0616-445f-93dd-1e58446eb6db"
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.manythings.org/anki/spa-eng.zip\n",
        "!unzip spa-eng.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-20 12:41:37--  http://www.manythings.org/anki/spa-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:30::6818:6cc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2819791 (2.7M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "\rspa-eng.zip           0%[                    ]       0  --.-KB/s               \rspa-eng.zip          31%[=====>              ] 867.84K  4.23MB/s               \rspa-eng.zip         100%[===================>]   2.69M  10.6MB/s    in 0.3s    \n",
            "\n",
            "2019-03-20 12:41:37 (10.6 MB/s) - ‘spa-eng.zip’ saved [2819791/2819791]\n",
            "\n",
            "Archive:  spa-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: spa.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1uWOB0LH3p-r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import (Dataset,DataLoader,TensorDataset)\n",
        "import tqdm\n",
        "\n",
        "import re\n",
        "import collections\n",
        "import itertools\n",
        "remove_marks_regex = re.compile(\n",
        "\"[\\,\\(\\)\\[\\]\\*:;¿¡]|<.*?>\")\n",
        "shift_marks_regex = re.compile(\"([?!\\.])\")\n",
        "unk = 0\n",
        "sos = 1\n",
        "eos = 2\n",
        "def normalize(text):\n",
        "  text = text.lower()\n",
        "  # 불필요한 문자 제거\n",
        "  text = remove_marks_regex.sub(\"\", text)\n",
        "  # ?!.와 단어 사이에 공백 삽입\n",
        "  text = shift_marks_regex.sub(r\" \\1\", text)\n",
        "  return text\n",
        "\n",
        "def parse_line(line):\n",
        "  line = normalize(line.strip())\n",
        "  # 번역 소스(src)와 번역 타깃(trg) 각각의 토큰을 리스트로 만든다\n",
        "  src, trg = line.split(\"\\t\")\n",
        "  src_tokens = src.strip().split()\n",
        "  trg_tokens = trg.strip().split()\n",
        "  return src_tokens, trg_tokens\n",
        "\n",
        "def build_vocab(tokens):\n",
        "  # 파일 안의 모든 문장에서 토큰의 등장 횟수를 확인\n",
        "  counts = collections.Counter(tokens)\n",
        "  # 토큰의 등장 횟수를 많은 순으로 나열\n",
        "  sorted_counts = sorted(counts.items(),\n",
        "  key=lambda c: c[1], reverse=True)\n",
        "  # 세 개의 태그를 추가해서 정방향 리스트와 역방향 용어집 만들기\n",
        "  word_list = [\"<UNK>\", \"<SOS>\", \"<EOS>\"] \\\n",
        "  + [x[0] for x in sorted_counts]\n",
        "  word_dict = dict((w, i) for i, w in enumerate(word_list))\n",
        "  return word_list, word_dict\n",
        "\n",
        "def words2tensor(words, word_dict, max_len, padding=0):\n",
        "  # 끝에 종료 태그를 붙임\n",
        "  words = words + [\"<EOS>\"]\n",
        "  # 사전을 이용해서 수치 리스트로 변환\n",
        "  words = [word_dict.get(w, 0) for w in words]\n",
        "  seq_len = len(words)\n",
        "  # 길이가 max_len 이하이면 패딩한다\n",
        "  if seq_len < max_len + 1:\n",
        "    words = words + [padding] * (max_len + 1 - seq_len)\n",
        "  # 텐서로 변환해서 반환\n",
        "  return torch.tensor(words, dtype=torch.int64), seq_len\n",
        "\n",
        "class TranslationPairDataset(Dataset):\n",
        "    def __init__(self, path, max_len=15):\n",
        "        # 단어 수사 많은 문장을 걸러내는 함수\n",
        "        def filter_pair(p):\n",
        "            return not (len(p[0]) > max_len \n",
        "                        or len(p[1]) > max_len)\n",
        "        # 파일을 열어서, 파스 및 필터링       \n",
        "        with open(path) as fp:\n",
        "            pairs = map(parse_line, fp)\n",
        "            pairs = filter(filter_pair, pairs)\n",
        "            pairs = list(pairs)\n",
        "        # 문장의 소스와 타켓으로 나눔\n",
        "        src = [p[0] for p in pairs]\n",
        "        trg = [p[1] for p in pairs]\n",
        "        #각각의 어휘집 작성\n",
        "        self.src_word_list, self.src_word_dict = \\\n",
        "            build_vocab(itertools.chain.from_iterable(src))\n",
        "        self.trg_word_list, self.trg_word_dict = \\\n",
        "            build_vocab(itertools.chain.from_iterable(trg))\n",
        "        # 어휘집을 사용해서 Tensor로 변환\n",
        "        self.src_data = [words2tensor(\n",
        "            words, self.src_word_dict, max_len)\n",
        "                for words in src]\n",
        "        self.trg_data = [words2tensor(\n",
        "            words, self.trg_word_dict, max_len, -100)\n",
        "                         for words in trg]\n",
        "    def __len__(self):\n",
        "        return len(self.src_data)\n",
        "      \n",
        "    def __getitem__(self, idx):\n",
        "        src, lsrc = self.src_data[idx]\n",
        "        trg, ltrg = self.trg_data[idx]\n",
        "        return src, lsrc, trg, ltrg\n",
        "      \n",
        "batch_size = 64\n",
        "max_len = 10\n",
        "path = \"/content/spa.txt\"\n",
        "ds = TranslationPairDataset(path, max_len=max_len)\n",
        "loader = DataLoader(ds, batch_size=batch_size, shuffle=True,\n",
        "                    num_workers=4)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_embeddings,\n",
        "                 embedding_dim=50, \n",
        "                  hidden_size=50,\n",
        "                 num_layers=1,\n",
        "                 dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(num_embeddings, \n",
        "          embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            hidden_size, num_layers,\n",
        "                            batch_first=True, dropout=dropout)\n",
        "        \n",
        "    def forward(self, x, h0=None, l=None):\n",
        "        x = self.emb(x)\n",
        "        if l is not None:\n",
        "            x = nn.utils.rnn.pack_padded_sequence(\n",
        "                x, l, batch_first=True)\n",
        "        _, h = self.lstm(x, h0)\n",
        "        return h\n",
        "      \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_embeddings,\n",
        "                 embedding_dim=50, \n",
        "                 hidden_size=50,\n",
        "                 num_layers=1,\n",
        "                 dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size,\n",
        "                            num_layers, batch_first=True,\n",
        "                            dropout=dropout)\n",
        "        self.linear = nn.Linear(hidden_size, num_embeddings)\n",
        "    \n",
        "    def forward(self, x, h, l=None):\n",
        "        x = self.emb(x)\n",
        "        if l is not None:\n",
        "            x = nn.utils.rnn.pack_padded_sequence(\n",
        "                x, l, batch_first=True)\n",
        "        x, h = self.lstm(x, h)\n",
        "        if l is not None:\n",
        "            x = nn.utils.rnn.pad_packed_sequence(x, batch_first=True, padding_value=0)[0]\n",
        "        x = self.linear(x)\n",
        "        return x, h\n",
        "      \n",
        "def translate(input_str, enc, dec, max_len=15, device=\"cpu\"):\n",
        "    # 입력 문자열을 수치화해서 Tensor로 변환\n",
        "    words = normalize(input_str).split()\n",
        "    input_tensor, seq_len = words2tensor(words, \n",
        "        ds.src_word_dict, max_len=max_len)\n",
        "    input_tensor = input_tensor.unsqueeze(0)\n",
        "    # 엔코더에서 사용하므로 입력값의 길이도 리스트로 만들어둔다\n",
        "    seq_len = [seq_len]\n",
        "    # 시작 토큰 준비\n",
        "    sos_inputs = torch.tensor(sos, dtype=torch.int64)\n",
        "    input_tensor = input_tensor.to(device)\n",
        "    sos_inputs = sos_inputs.to(device)\n",
        "    # 입력 문자열을 엔코더에 넣어서 컨텍스트 얻기\n",
        "    ctx = enc(input_tensor, l=seq_len)\n",
        "    # 시작 토큰과 컨텍스트를 디코더의 초깃값으로 설정\n",
        "    z = sos_inputs\n",
        "    h = ctx\n",
        "    results = []\n",
        "    for i in range(max_len):\n",
        "        # Decoder로 다음 단어 예측\n",
        "        o, h = dec(z.view(1, 1), h)\n",
        "        # 선형 계층의 출력이 가장 큰 위치가 다음 단어의 ID\n",
        "        wi = o.detach().view(-1).max(0)[1]\n",
        "        if wi.item() == eos:\n",
        "            break\n",
        "        results.append(wi.item())\n",
        "        # 다음 입력값으로 현재 출력 ID를 사용\n",
        "        z = wi\n",
        "    # 기록해둔 출력 ID를 문자열로 변환\n",
        "    return \" \".join(ds.trg_word_list[i] for i in results)\n",
        "\n",
        "''''' 테스트\n",
        "enc = Encoder(len(ds.src_word_list), 100, 100, 2)\n",
        "dec = Decoder(len(ds.trg_word_list), 100, 100, 2)\n",
        "translate(\"I am a student.\", enc, dec)\n",
        "'''''\n",
        "\n",
        "enc = Encoder(len(ds.src_word_list), 100, 100, 2)\n",
        "dec = Decoder(len(ds.trg_word_list), 100, 100, 2)\n",
        "enc.to(\"cuda:0\")\n",
        "dec.to(\"cuda:0\")\n",
        "opt_enc = optim.Adam(enc.parameters(), 0.002)\n",
        "opt_dec = optim.Adam(dec.parameters(), 0.002)\n",
        "loss_f = nn.CrossEntropyLoss()\n",
        "\n",
        "from statistics import mean\n",
        "\n",
        "def to2D(x):\n",
        "    shapes = x.shape\n",
        "    return x.reshape(shapes[0] * shapes[1], -1)\n",
        "  \n",
        "for epoc in range(30):\n",
        "    # 신경망을 훈련 모드로 설정\n",
        "    enc.train(), dec.train()\n",
        "    losses = []\n",
        "    for x, lx, y, ly in tqdm.tqdm(loader):\n",
        "        # x의 PackedSequence를 만들기 위해 번역 소스의 길이로 내림차순 정렬한다\n",
        "        lx, sort_idx = lx.sort(descending=True)\n",
        "        x, y, ly = x[sort_idx], y[sort_idx], ly[sort_idx]\n",
        "        x, y = x.to(\"cuda:0\"), y.to(\"cuda:0\")\n",
        "        # 번역 소스를 엔코더에 넣어서 컨텍스트를 얻는다\n",
        "        ctx = enc(x, l=lx)\n",
        "        # y의 PackedSequence를 만들기 위해 번역 소스의 길이로 내림차순 정렬\n",
        "        ly, sort_idx = ly.sort(descending=True)\n",
        "        y = y[sort_idx]\n",
        "        # Decoder의 초깃값 설정\n",
        "        h0 = (ctx[0][:, sort_idx, :], ctx[1][:, sort_idx, :])\n",
        "        z = y[:, :-1].detach()\n",
        "        # -100인 상태에선 Embedding 계산에서 오류가 발생하므로 0으로 변경\n",
        "        z[z==-100] = 0\n",
        "        # 디코더에 넣어서 손실 함수 계산\n",
        "        o, _ = dec(z, h0, l=ly-1)\n",
        "        loss = loss_f(to2D(o[:]), to2D(y[:, 1:max(ly)]).squeeze())\n",
        "        # Backpropagation(오차 역전파 실행)\n",
        "        enc.zero_grad(), dec.zero_grad()\n",
        "        loss.backward()\n",
        "        opt_enc.step(), opt_dec.step()\n",
        "        losses.append(loss.item())\n",
        "    # 전체 데이터의 계산이 끝나면 현재의\n",
        "    # 손실 함수 값이나 번역 결과를 표시\n",
        "    enc.eval(), dec.eval()\n",
        "    print(epoc, mean(losses))\n",
        "    with torch.no_grad():\n",
        "        print(translate(\"I am a student.\",\n",
        "                         enc, dec, max_len=max_len, device=\"cuda:0\"))\n",
        "        print(translate(\"He likes to eat pizza.\",\n",
        "                         enc, dec, max_len=max_len, device=\"cuda:0\"))\n",
        "        print(translate(\"She is my mother.\",\n",
        "                         enc, dec, max_len=max_len, device=\"cuda:0\"))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}