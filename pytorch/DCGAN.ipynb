{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drvoss/Colab-Notebooks/blob/master/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "AHs639h0w0z1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n",
        "!tar xf 102flowers.tgz\n",
        "!mkdir oxford-102\n",
        "!mkdir oxford-102/jpg\n",
        "!mv jpg/*.jpg oxford-102/jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LDTltBF6wWdL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import (Dataset,DataLoader,TensorDataset)\n",
        "import tqdm\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "img_data = ImageFolder(\"/content/oxford-102/\",\n",
        "  transform=transforms.Compose([\n",
        "  transforms.Resize(80),\n",
        "  transforms.CenterCrop(64),\n",
        "  transforms.ToTensor()\n",
        "]))\n",
        "batch_size = 64\n",
        "img_loader = DataLoader(img_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#이미지 생성모델 구축\n",
        "nz = 100\n",
        "ngf = 32\n",
        "class GNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.main = nn.Sequential(\n",
        "      nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "      nn.BatchNorm2d(ngf * 8),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ngf * 4),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ngf * 2),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ngf),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
        "      nn.Tanh()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    out = self.main(x)\n",
        "    return out\n",
        "\n",
        "#이미지 식별모델 구축\n",
        "ndf = 32\n",
        "class DNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.main = nn.Sequential(\n",
        "      nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ndf * 2),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ndf * 4),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ndf * 8),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    out = self.main(x)\n",
        "    return out.squeeze()\n",
        "  \n",
        "d = DNet().to(\"cuda:0\")\n",
        "g = GNet().to(\"cuda:0\")\n",
        "\n",
        "# Adam의 파라미터는 원 논문에서 제안하는 값\n",
        "opt_d = optim.Adam(d.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "opt_g = optim.Adam(g.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# 크로스 엔트로피를 계산하기 위한 보조 변수 등\n",
        "ones = torch.ones(batch_size).to(\"cuda:0\")\n",
        "zeros = torch.zeros(batch_size).to(\"cuda:0\")\n",
        "loss_f = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# 모니터링용 z\n",
        "fixed_z = torch.randn(batch_size, nz, 1, 1).to(\"cuda:0\")\n",
        "\n",
        "from statistics import mean\n",
        "def train_dcgan(g, d, opt_g, opt_d, loader):\n",
        "  # 생성 모델, 식별 모델의 목적 함수 추적용 배열\n",
        "  log_loss_g = []\n",
        "  log_loss_d = []\n",
        "  for real_img, _ in tqdm.tqdm(loader):\n",
        "    batch_len = len(real_img)\n",
        "    # 실제 이미지를 GPU로 복사\n",
        "    real_img = real_img.to(\"cuda:0\")\n",
        "    # 가짜 이미지를 난수와 생성 모델을 사용해 만든다\n",
        "    z = torch.randn(batch_len, nz, 1, 1).to(\"cuda:0\")\n",
        "    fake_img = g(z)\n",
        "    # 나중에 사용하기 위해서 가짜 이미지의 값만 별도로 저장해 둠\n",
        "    fake_img_tensor = fake_img.detach()\n",
        "    # 가짜 이미지에 대한 생성 모델의 평가 함수 계산\n",
        "    out = d(fake_img)\n",
        "    loss_g = loss_f(out, ones[: batch_len])\n",
        "    log_loss_g.append(loss_g.item())\n",
        "    # 계산 그래프가 생성 모델과 식별 모델 양쪽에\n",
        "    # 의존하므로 양쪽 모두 경사하강을 끝낸 후에\n",
        "    # 미분 계산과 파라미터 갱신을 실시\n",
        "    d.zero_grad(), g.zero_grad()\n",
        "    loss_g.backward()\n",
        "    opt_g.step()\n",
        "    # 실제 이미지에 대한 식별 모델의 평가 함수 계산\n",
        "    real_out = d(real_img)\n",
        "    loss_d_real = loss_f(real_out, ones[: batch_len])\n",
        "    # 파이토치에서는 동일 텐서를 포함한 계산 그래프에\n",
        "    # 2회 backward를 할 수 없으므로 저장된 텐서를\n",
        "    # 사용해서 불필요한 계산은 생략\n",
        "    fake_img = fake_img_tensor\n",
        "    # 가짜 이미지에 대한 식별 모델의 평가 함수 계산\n",
        "    fake_out = d(fake_img_tensor)\n",
        "    loss_d_fake = loss_f(fake_out, zeros[: batch_len])\n",
        "    # 진위 평가 함수의 합계\n",
        "    loss_d = loss_d_real + loss_d_fake\n",
        "    log_loss_d.append(loss_d.item())\n",
        "    # 식별 모델의 미분 계산과 파라미터 갱신\n",
        "    d.zero_grad(), g.zero_grad()\n",
        "    loss_d.backward()\n",
        "    opt_d.step()\n",
        "  return mean(log_loss_g), mean(log_loss_d)\n",
        "\n",
        "for epoch in range(300):\n",
        "  train_dcgan(g, d, opt_g, opt_d, img_loader)\n",
        "  # 10회 반복마다 학습 결과를 저장\n",
        "  if epoch % 10 == 0:\n",
        "    # 파라미터 저장\n",
        "    torch.save(g.state_dict(), \"/content/g_{:03d}.prm\".format(epoch), pickle_protocol=4)\n",
        "    torch.save(d.state_dict(), \"/content/d_{:03d}.prm\".format(epoch), pickle_protocol=4)\n",
        "    # 모니터링용 z로부터 생성한 이미지 저장\n",
        "    generated_img = g(fixed_z)\n",
        "    save_image(generated_img, \"/content/{:03d}.jpg\".format(epoch))\n",
        "    \n",
        "from IPython.display import Image,display_jpeg\n",
        "display_jpeg(Image('oxford-102/000.jpg'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}